{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1276cc8-fddc-4996-b720-a1419890bc7d",
   "metadata": {},
   "source": [
    "# Example ML pipeline using BODC data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2b6f1d-fd05-4ebd-986d-6941f9caa738",
   "metadata": {},
   "source": [
    "A simple overview for retrieving data from a croissant file and training a simple machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cfed2e-427f-41fc-81de-6f9181b56b5c",
   "metadata": {},
   "source": [
    "## Notebook overview\n",
    "\n",
    "This notebook loads a croissant file and trains a simple machine learning model using the darts library to forecast unseen bottom pressure recorder data. This is purely intended to be a proof of concept, to demonstrate that data can be obtained via a croissant file, and then used to train a machine learning model.\n",
    "\n",
    "### Data\n",
    "https://www.bodc.ac.uk/resources/inventories/edmed/report/155/ \n",
    "\n",
    "The data set comprises time series measurements from offshore pressure gauges mounted on the sea floor. The data holdings are approximately 250 observation months from 100 sites. The data have mainly been collected in the continental shelf seas around the British Isles. Data records contain date/time, total pressure and, occasionally, temperature. The sampling interval is typically 15 minutes or hourly, over deployment periods ranging from 1 to 6 months. Data were collected mainly by the Proudman Oceanographic Laboratory (POL), now the National Oceanography Centre (NOC) at Liverpool, and are managed by the British Oceanographic Data Centre (BODC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6064825-ce6d-4259-91b4-529e76d7ee1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from io import BytesIO\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts import TimeSeries\n",
    "from darts.models import NBEATSModel\n",
    "\n",
    "\n",
    "import mlcroissant as mlc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823fa1cd-2187-4350-b338-9895c7352536",
   "metadata": {},
   "source": [
    "## Get & prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adae5ff-832c-4c44-a3cd-fc033ecb02d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_flag(val):\n",
    "    # find flagged data\n",
    "    if str(val)[-1] in [\"M\"]:\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "\n",
    "def replace_bad(val):\n",
    "    # parse flagged data\n",
    "    if str(val)[-1] in [\"M\", \"N\"]:\n",
    "        return np.nan\n",
    "    return val\n",
    "\n",
    "\n",
    "def make_datetime(d, t):\n",
    "    # format separate columns as a datetime object\n",
    "    dt = d + t\n",
    "    return datetime.strptime(dt, \"%Y/%m/%d%H.%M.%S\")\n",
    "\n",
    "\n",
    "def read_croissant(str_obj):\n",
    "    # read croissant file and process as a pandas df\n",
    "    # multiple variables in these files: we only want to get PPSCZZ01 data.\n",
    "\n",
    "    if \"PPSCZZ01\" in str(str_obj):\n",
    "        df = pd.read_csv(\n",
    "            BytesIO(str_obj),\n",
    "            skiprows=13,\n",
    "            sep=\"[ ^]+\",\n",
    "            names=[\"row_num\", \"date\", \"time\", \"pressure\"],\n",
    "            engine=\"python\",\n",
    "        )\n",
    "        df[\"qc_flag\"] = df[\"pressure\"].apply(find_flag)\n",
    "        df[\"pressure\"] = df[\"pressure\"].apply(replace_bad).astype(float)\n",
    "        df[\"datetime\"] = df.apply(lambda x: make_datetime(x.date, x.time), axis=1)\n",
    "        df[\"datetime\"] = df[\"datetime\"].dt.floor(\"Min\")\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab598651-cd6d-4d78-bb85-5756d7ae0c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = mlc.Dataset(\"shelfbpr_bodc.json\")\n",
    "dfs = []\n",
    "for f in ds.records(record_set=\"default\"):\n",
    "    out = read_croissant(f[\"dat/content\"])\n",
    "    if out is not None:\n",
    "        dfs.append(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91308dd-114a-4741-97ba-10fc6c8bca93",
   "metadata": {},
   "source": [
    "## Split into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14407992-b000-46c7-b279-56128dd859c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = []\n",
    "i = 0\n",
    "for df in dfs:\n",
    "    try:\n",
    "        df = TimeSeries.from_dataframe(\n",
    "            df[[\"datetime\", \"pressure\"]],\n",
    "            time_col=\"datetime\",\n",
    "            freq=\"15min\",\n",
    "            value_cols=\"pressure\",\n",
    "            fillna_value=0,\n",
    "        )\n",
    "        df = df.resample(freq=\"15min\", method=\"interpolate\")[1:]\n",
    "        time_series.append(df)\n",
    "    except Exception:\n",
    "        print(\n",
    "            \"skipping\",\n",
    "            i,\n",
    "        )\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1e253d-ed31-4455-8cac-7a60f628a5a4",
   "metadata": {},
   "source": [
    "## Produce TimeSeries objects ready for darts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c6e9db-4ed8-4188-8c00-a7956c4cce71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scale data too\n",
    "scaler = Scaler()\n",
    "scaled = scaler.fit_transform(time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e6a744-95e1-4f57-b251-c9b80a765abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split = 0.8\n",
    "\n",
    "split = int(train_test_split * len(scaled))\n",
    "train = scaled[:split]\n",
    "test = scaled[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578e517f",
   "metadata": {},
   "source": [
    "## Train model\n",
    "\n",
    "A GPU might be handy here (should be automatically detected): consider reducing the `train_test_split` if you're pushed for time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa03dc3-4824-47e1-a057-4ddba246c467",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NBEATSModel(input_chunk_length=192, output_chunk_length=96, random_state=42)\n",
    "\n",
    "model.fit(train, epochs=1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec680f72-4d62-40cd-aa8b-782d30de0359",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 192\n",
    "test_x, test_y = [], []\n",
    "for k in test:\n",
    "    test_x.append(k[:-n])\n",
    "    test_y.append(k[-n:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6836890",
   "metadata": {},
   "source": [
    "## Measure performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b73360-22f8-4330-b06b-75b261d7c5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(series=test_x, n=n)\n",
    "cvtd = scaler.inverse_transform(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee12190-08c4-41e6-a8dc-59fef5b3738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inverse = scaler.inverse_transform(test_x)\n",
    "truth_inverse = scaler.inverse_transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617f23f2-78b1-4ee1-9e39-a18ae6bbb76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some predictions\n",
    "for item in range(len(test_inverse)):\n",
    "    fig, ax = plt.subplots(figsize=(6, 3.5), layout=\"constrained\")\n",
    "    test_inverse[item][-2000:].plot(ax=ax, label=\"X\")\n",
    "    truth_inverse[item].plot(ax=ax, linestyle=\"-\", label=\"Ground Truth\", color=\"grey\")\n",
    "    cvtd[item].plot(ax=ax, label=\"Prediction\", linestyle=\":\")\n",
    "\n",
    "    fig.suptitle(\"Example (truncated) prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8d8e2f-dcaf-4a75-b23a-26f1e872f0ff",
   "metadata": {},
   "source": [
    "## Calculate skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4939be8d-1f96-47af-820a-0ed43f5bab4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use RMSE to calculate prediction skill\n",
    "from darts.metrics.metrics import rmse\n",
    "\n",
    "# there's plenty others out there in various documentation: this is just an example from darts\n",
    "\n",
    "rmses = rmse(truth_inverse, cvtd)\n",
    "print(rmses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ced9c3-15e0-49f7-bb17-245f9520ff2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
