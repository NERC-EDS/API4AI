{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "714074be-5222-4063-baee-087d7a1afc26",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This shows the work done for the UKCEH croissant spike.\n",
    "\n",
    "The purpose was to demonstrate extracting data from file(s) on our production catalogue (https://catalogue.ceh.ac.uk/) using a hard coded croissant.json file.\n",
    "\n",
    "Only example 1 worked, which shows extraction for a single fileObject.  Examples 2 and 3 show the work I did to try to access netcdf files with and without a login, and also trying to use a **fileSet** - which I now believe is only used against an archive fileObject (or other fileSets that eventually point to an archive fileObject). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11c087d-5fdd-4be1-8f69-89050c94c910",
   "metadata": {},
   "source": [
    "Install dependencies used across all cells of investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97f1d39-5945-413e-a9b5-1933deb6ccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests\n",
    "!pip install ipywidgets\n",
    "!pip install mlcroissant\n",
    "!pip install mlcroissant netCDF4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e56f7c-8c71-444e-af9d-4bfd70a9a9f3",
   "metadata": {},
   "source": [
    "## Example 1 - successfully access a single csv file from archived and unarchived downloads\n",
    "This demonstrates extracting columns from csv files that are downloaded as archived (zip) and unarchived (raw csv) files.\n",
    "\n",
    "All files are freely available and need no login.\n",
    "\n",
    "All data available via OGL license.\n",
    "\n",
    "1. Archived\n",
    "   croissantSpikeZip.json is the croissant file for an archived dataset that is downloaded as a zip file.\n",
    "   Full information for this dataset is [here](https://catalogue.ceh.ac.uk/documents/972599af-0cc3-4e0e-a4dc-2fab7a6dfc85).\n",
    "   It contains 4 csv files for sand dune data, with up to ~30,000 rows per file.\n",
    "\n",
    "2. Unarchived\n",
    "   croissantSpikeCOSMOSSingle.json is a croissant file that points to a couple of raw csv download files.\n",
    "   Full information for this dataset is [here](https://catalogue.ceh.ac.uk/documents/399ed9b1-bf59-4d85-9832-ee4d29f49bfb)\n",
    "   Just a couple of csv's are used from the full set of about 1300 csv links available [here](https://catalogue.ceh.ac.uk/datastore/eidchub/399ed9b1-bf59-4d85-9832-ee4d29f49bfb/).\n",
    "\n",
    "I have not yet worked out how to extract data from subsets of csv files in the archive (zip) file using a 'fileSet' and glob pattern  - this would be very useful for archive files that contain many files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "ee8e779c-4157-4c7c-bf6b-dc3f7023b0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 91619, 'X': 235341.25, 'Y': 368183.75, 'Aspect': 147.3955898, 'Slope': 5.947185636, 'WindSpeed': 1.552845}\n",
      "{'id': 91620, 'X': 235341.25, 'Y': 368181.25, 'Aspect': 183.3925629, 'Slope': 7.696038723, 'WindSpeed': 1.6105891}\n",
      "{'id': 91621, 'X': 235341.25, 'Y': 368178.75, 'Aspect': 174.296432, 'Slope': 5.170789957, 'WindSpeed': 1.5677601}\n",
      "{'id': 91622, 'X': 235341.25, 'Y': 368176.25, 'Aspect': 264.8109093, 'Slope': 2.708107293, 'WindSpeed': 1.4615709}\n",
      "{'id': 91623, 'X': 235341.25, 'Y': 368173.75, 'Aspect': 172.1959329, 'Slope': 11.81059909, 'WindSpeed': 1.4316834}\n",
      "{'id': 91624, 'X': 235341.25, 'Y': 368171.25, 'Aspect': 255.1948204, 'Slope': 7.329361081, 'WindSpeed': 1.814988}\n",
      "{'id': 91625, 'X': 235341.25, 'Y': 368168.75, 'Aspect': 206.2561874, 'Slope': 6.884741783, 'WindSpeed': 1.6822661}\n",
      "{'id': 91626, 'X': 235341.25, 'Y': 368166.25, 'Aspect': 237.1464386, 'Slope': 8.261778951, 'WindSpeed': 1.4579354}\n",
      "{'id': 91627, 'X': 235341.25, 'Y': 368163.75, 'Aspect': 240.042305, 'Slope': 5.523819923, 'WindSpeed': 1.4785903}\n",
      "{'id': 91628, 'X': 235341.25, 'Y': 368161.25, 'Aspect': 270.6544495, 'Slope': 10.4367075, 'WindSpeed': 1.2462929}\n",
      "{'id': 91629, 'X': 235341.25, 'Y': 368158.75, 'Aspect': 281.7114868, 'Slope': 14.4877305, 'WindSpeed': 0.99423441}\n",
      "{'id': 92159, 'X': 235343.75, 'Y': 368193.75, 'Aspect': 257.6832695, 'Slope': 11.59320092, 'WindSpeed': 1.5860065}\n",
      "{'lwin': -9999.0, 'lwout': -9999.0}\n",
      "{'lwin': 28.5, 'lwout': 34.1}\n",
      "{'lwin': 30.8, 'lwout': 32.8}\n",
      "{'lwin': 29.7, 'lwout': 33.6}\n",
      "{'lwin': 29.0, 'lwout': 33.9}\n",
      "{'lwin': 31.6, 'lwout': 32.9}\n",
      "{'lwin': 28.3, 'lwout': 34.4}\n",
      "{'lwin': 28.5, 'lwout': 31.7}\n",
      "{'lwin': 28.3, 'lwout': 32.5}\n",
      "{'lwin': 29.0, 'lwout': 32.9}\n",
      "{'lwin': 30.5, 'lwout': 32.1}\n",
      "{'lwin': 29.6, 'lwout': 33.3}\n"
     ]
    }
   ],
   "source": [
    "import mlcroissant as mlc\n",
    "\n",
    "def doML(url, recordsetId):\n",
    "    dataset = mlc.Dataset(jsonld=url)\n",
    "    \n",
    "    dataset = mlc.Dataset(jsonld=url)\n",
    "    records = dataset.records(record_set=recordsetId)\n",
    "    for i, record in enumerate(records):\n",
    "      print(record)\n",
    "      if i > 10:\n",
    "        break\n",
    "      \n",
    "doML('croissantSpikeZip.json', 'rs-abberfraw')  # This one demostrates accessing a zip file containing 4 csv files and extracting a set of columns from one of them\n",
    "\n",
    "doML('croissantSpikeCOSMOSSingle.json', 'rs-one-file') # This one demonstrates acccessing columns of a single csv downloaded directly ie not in an archive file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a826db0-7edc-4add-85bc-73a66147d4b0",
   "metadata": {},
   "source": [
    "## Example 2 - fail to handle freely available netcdf files\n",
    "This example shows the work I did to try (and fail) to access netcdf files that are freely available - no login required.\n",
    "\n",
    "It tries to access the netcdf files of the Hadukgrid dataset, which contains links to many netcdf files [here](https://catalogue.ceh.ac.uk/datastore/eidchub/beb62085-ba81-480c-9ed0-2d31c27ff196/).\n",
    "\n",
    "Files have to be downloaded individually as there is no archive file available.\n",
    "\n",
    "I could not work out how to define a netcdf 'dataType' and get the 'extract' working in the recordSet, also I don't think I've got the fileSet correct.  In hindsight I could change it to access individual netcdf files successfully (as in example 1), but still not handle the netcdf format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e644f73-ec4e-4572-8ed0-224029837fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlcroissant as mlc\n",
    "import netCDF4 as nc\n",
    "   \n",
    "def doML(url, recordsetId):\n",
    "    dataset = mlc.Dataset(jsonld=url)\n",
    "    \n",
    "    dataset = mlc.Dataset(jsonld=url)\n",
    "    records = dataset.records(record_set=recordsetId)\n",
    "    for i, record in enumerate(records): # <-- It fails here because I can't workout what the 'dataType' should be nor the 'extract'  should be in the recordSet of the croissant file - time to use an easier csv example dataset!\n",
    "      print(record)\n",
    "      if i > 10:\n",
    "        break\n",
    "      \n",
    "doML('croissantSpikeHadukgrid.json', 'rs/file-set-dtr-preOct')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d35abe-dbcb-4115-be54-4aa1b04c140e",
   "metadata": {},
   "source": [
    "## Example 3 - using credentials\n",
    "\n",
    "This uses credentials to access CHESS netcdf files.  I have proven it works using my credentials.\n",
    "\n",
    "If required, create a new account [here](https://catalogue.ceh.ac.uk/sso/signup).  You may have to agree a license to use the dataset in this example.\n",
    "\n",
    "Unfortunately, I haven't yet worked out how to work with netcdf files, so whilst it downloads the netcdf file, it fails to extract data.\n",
    "\n",
    "The source files are hierachically organised, starting [here](https://catalogue.ceh.ac.uk/datastore/eidchub/835a50df-e74f-4bfb-b593-804fd61d5eab/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22097a6-cb4b-4122-93b0-52a1badbb4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlcroissant as mlc\n",
    "import netCDF4 as nc\n",
    "\n",
    "os.environ[\"CROISSANT_BASIC_AUTH_USERNAME\"] = \"myusername\"\n",
    "os.environ[\"CROISSANT_BASIC_AUTH_PASSWORD\"] = \"mypassword\"\n",
    "def doML(url, recordsetId):\n",
    "    dataset = mlc.Dataset(jsonld=url)\n",
    "    \n",
    "    dataset = mlc.Dataset(jsonld=url)\n",
    "    records = dataset.records(record_set=recordsetId)\n",
    "    for i, record in enumerate(records): # <-- It fails here because I can't workout what the 'dataType' should be nor the 'extract'  should be in the recordSet of the croissant file - time to use an easier csv example dataset!\n",
    "      print(record)\n",
    "      if i > 10:\n",
    "        break\n",
    "      \n",
    "doML('croissantSpikeChess.json', 'rs-abberfraw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2359cd-3870-40f0-8420-4d4ce2452eac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
