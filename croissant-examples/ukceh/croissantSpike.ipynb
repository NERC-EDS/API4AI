{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "714074be-5222-4063-baee-087d7a1afc26",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This shows the work done for the UKCEH croissant spike.\n",
    "\n",
    "The purpose was to demonstrate extracting data from file(s) on our production catalogue (https://catalogue.ceh.ac.uk/) using a hard coded croissant.json file.\n",
    "\n",
    "Only example 1 worked, which shows extraction for a single fileObject.  Examples 2 and 3 show the work I did to try to access netcdf files with and without a login, and also trying to use a **fileSet** - which I now believe is only used against an archive fileObject (or other fileSets that eventually point to an archive fileObject). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11c087d-5fdd-4be1-8f69-89050c94c910",
   "metadata": {},
   "source": [
    "Install dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97f1d39-5945-413e-a9b5-1933deb6ccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets\n",
    "!pip install mlcroissant\n",
    "!pip install netCDF4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e56f7c-8c71-444e-af9d-4bfd70a9a9f3",
   "metadata": {},
   "source": [
    "## Example 1 - successfully access a single csv file from archived and unarchived downloads\n",
    "This demonstrates extracting columns from csv files that are downloaded as archived (zip) and unarchived (raw csv) files.\n",
    "\n",
    "All files are freely available and need no login.\n",
    "\n",
    "All data available via OGL license.\n",
    "\n",
    "1. Archived\n",
    "   croissantSpikeZip.json is the croissant file for an archived dataset that is downloaded as a zip file.\n",
    "   Full information for this dataset is [here](https://catalogue.ceh.ac.uk/documents/972599af-0cc3-4e0e-a4dc-2fab7a6dfc85).\n",
    "   It contains 4 csv files for sand dune data, with up to ~30,000 rows per file.\n",
    "\n",
    "2. Unarchived\n",
    "   croissantSpikeCOSMOSEdited.json is a working version of croissantSpikeCOSMOS.json.  It fixes some issues with the latter, but both have been kept for now for comparison. The working version lists 255 fileObjects, and has 1 recordSet that downloads all 44 fields from one of those fileObjects.\n",
    "   Full information for this dataset is [here](https://catalogue.ceh.ac.uk/documents/399ed9b1-bf59-4d85-9832-ee4d29f49bfb)\n",
    "   All downloadable files are [here](https://catalogue.ceh.ac.uk/datastore/eidchub/399ed9b1-bf59-4d85-9832-ee4d29f49bfb/).\n",
    "\n",
    "I have not yet worked out how to extract data from subsets of csv files in either the  archive or non-archive files using a 'fileSet' and glob pattern  - this would be very useful for archive files that contain many files, and long distribution lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8e779c-4157-4c7c-bf6b-dc3f7023b0e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import mlcroissant as mlc\n",
    "\n",
    "def doML(url, recordsetId):\n",
    "    dataset = mlc.Dataset(jsonld=url)\n",
    "    \n",
    "    dataset = mlc.Dataset(jsonld=url)\n",
    "    records = dataset.records(record_set=recordsetId)\n",
    "    for i, record in enumerate(records):\n",
    "      print(record)\n",
    "      if i > 10:\n",
    "        break\n",
    "      \n",
    "doML('croissantSpikeZip.json', 'rs-abberfraw')  # This one demostrates accessing a zip file containing 4 csv files and extracting a set of columns from one of them\n",
    "\n",
    "doML('croissantSpikeCOSMOSEdited.json', 'rs-cosmos') # This one demonstrates acccessing columns of a single csv downloaded directly ie not in an archive file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d35abe-dbcb-4115-be54-4aa1b04c140e",
   "metadata": {},
   "source": [
    "## Example 2 - successfully use credentials to download (but not extract from) netcdf\n",
    "\n",
    "This uses credentials to access CHESS netcdf files.  I have proven it works using my credentials.\n",
    "\n",
    "Run the first cell once to set your login credentials, then run the second cell to download the data.\n",
    "\n",
    "If required, create a new account [here](https://catalogue.ceh.ac.uk/sso/signup).  You may have to agree a license to use the dataset in this example.\n",
    "\n",
    "Unfortunately, I haven't yet worked out how to extract data from the netcdf files, so whilst it downloads the netcdf file, it fails to extract data.\n",
    "\n",
    "The source files are hierachically organised, starting [here](https://catalogue.ceh.ac.uk/datastore/eidchub/835a50df-e74f-4bfb-b593-804fd61d5eab/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ff1cd5-d417-4938-96de-fe9bcc6a96f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set credentials\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Create widgets for username and password\n",
    "username = widgets.Text(description='Username:')\n",
    "password = widgets.Password(description='Password:')\n",
    "login_button = widgets.Button(description='Login')\n",
    "\n",
    "# Get user credentials and set as envars\n",
    "def login(button):\n",
    "    os.environ[\"CROISSANT_BASIC_AUTH_USERNAME\"] = username.value\n",
    "    os.environ[\"CROISSANT_BASIC_AUTH_PASSWORD\"] = password.value\n",
    "\n",
    "# Attach the login function to the button\n",
    "login_button.on_click(login)\n",
    "\n",
    "# Display the widgets\n",
    "display(\"Login to UKCEH's catalogue to download data.  If required, create an account at https://catalogue.ceh.ac.uk/sso/signup\", username, password, login_button)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22097a6-cb4b-4122-93b0-52a1badbb4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlcroissant as mlc\n",
    "import netCDF4 as nc\n",
    "\n",
    "def doML(url, recordsetId):\n",
    "    dataset = mlc.Dataset(jsonld=url)\n",
    "    records = dataset.records(record_set=recordsetId)\n",
    "    for i, record in enumerate(records): # <-- It fails here because I can't workout what the 'dataType' should be nor the 'extract'  should be in the recordSet of the croissant file - time to use an easier csv example dataset!\n",
    "      print(record)\n",
    "      if i > 10:\n",
    "        break\n",
    "          \n",
    "doML('croissantSpikeChess.json', 'rs-abberfraw')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
