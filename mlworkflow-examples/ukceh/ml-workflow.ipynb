{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Croissant in Machine Learning Pipelines ü•ê"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Croissant provides a single-file JSON-LD format for Machine Learning (ML) datasets that contains information about data sources, data structure and relevant additional metadata. The standardized format aims to improve the discoverability, accessibility, and interoperability of ML datasets. In this notebook we'll demonstrate using an example croissant file (linked to a dataset from the UKCEH Environment Information Data Centre (EIDC)) in an ML-pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing necessary libraries\n",
    "%%capture --no-display\n",
    "# Install mlcroissant from the source\n",
    "!apt-get install -y python3-dev graphviz libgraphviz-dev pkg-config\n",
    "!pip install \"git+https://github.com/${GITHUB_REPOSITORY:-mlcommons/croissant}.git@${GITHUB_HEAD_REF:-main}#subdirectory=python/mlcroissant&egg=mlcroissant[dev]\"\n",
    "!pip install array_record\n",
    "!pip install tfds-nightly\n",
    "!pip install tensorflow\n",
    "!pip install torch\n",
    "!apt-get install tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import json\n",
    "import os\n",
    "from etils import epath\n",
    "import mlcroissant as mlc\n",
    "import requests\n",
    "import tensorflow_datasets as tfds\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently the underlying data described in the croissant file can be loaded directly using either the [mlcroissant](https://github.com/mlcommons/croissant/tree/main/python/mlcroissant) python library or the [tensorflow croissant builder](https://www.tensorflow.org/datasets/format_specific_dataset_builders#croissantbuilder). Here we'll demonstrate both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from the croissant file using mlcroissant\n",
    "croissant_file_path = \"/tmp/croissantSpikeZip.json\" #\"../../croissantSpikeZip.json\"\n",
    "dataset = Dataset(jsonld=croissant_file_path)  # Use mlc.Dataset to parse Croissant metadata\n",
    "metadata = dataset.metadata.to_json() # Convert the metadata to a JSON object\n",
    "records = dataset.records(record_set=\"rs-abberfraw\") # Extract records from the dataset\n",
    "df = pd.DataFrame(records) # Convert the records to a pandas dataframe \n",
    "df[:5] # Display the first 5 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from the croissant file using tensorflow custom builder\n",
    "builder = tfds.core.dataset_builders.CroissantBuilder(\n",
    "    jsonld=\"/tmp/croissantSpikeZip.json\",\n",
    "    record_set_ids=[\"rs-abberfraw\"],\n",
    "    file_format='array_record',\n",
    "    data_dir=\"/tmp/croissant_ukceh\",\n",
    ")\n",
    "print(f\"Dataset's description:\\n{builder.info.description}\\n\")\n",
    "print(f\"Dataset's citation:\\n{builder.info.citation}\\n\")\n",
    "print(f\"Dataset's features:\\n{builder.info.features}\")\n",
    "\n",
    "builder.download_and_prepare() # Download and prepare the dataset\n",
    "datasource = builder.as_data_source() \n",
    "for i in datasource['default'][:10]:\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
